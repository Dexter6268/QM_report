{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Workflow\n",
    "\n",
    "This notebook demonstrates the research [workflow](https://langchain-ai.github.io/langgraph/tutorials/workflows/) that creates comprehensive reports through a series of focused steps. The system:\n",
    "\n",
    "1. Uses a **graph workflow** with specialized nodes for each report creation stage\n",
    "2. Enables user **feedback and approval** at critical planning points \n",
    "3. Produces a well-structured report with introduction, researched body sections, and conclusion\n",
    "\n",
    "## From repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\62687\\Desktop\\个人\\实习相关\\标准化研究院实习\\QM_report\\src\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the Graph-Based Research Workflow\n",
    "\n",
    "The next step is to compile the LangGraph workflow that orchestrates the report creation process. This defines the sequence of operations and decision points in the research pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.15\n",
      "builder compiling ...\n",
      "builder compiled.\n",
      "deepseek-chat\n",
      "deepseek\n"
     ]
    }
   ],
   "source": [
    "# Import required modules and initialize the builder from open_deep_research\n",
    "import uuid \n",
    "import os, getpass\n",
    "import open_deep_research   \n",
    "print(open_deep_research.__version__) \n",
    "from IPython.display import Image, display, Markdown\n",
    "from langgraph.types import Command\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from open_deep_research.graph import builder\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Create a memory-based checkpointer and compile the graph\n",
    "# This enables state persistence and tracking throughout the workflow execution\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "load_dotenv(\"../.env\")\n",
    "print(os.environ[\"PLANNER_MODEL\"])\n",
    "print(os.environ[\"PLANNER_PROVIDER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "builder compiling ...\n",
      "builder compiled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'open_deep_research.graph' from 'c:\\\\Users\\\\62687\\\\Desktop\\\\个人\\\\实习相关\\\\标准化研究院实习\\\\open_deep_research\\\\src\\\\open_deep_research\\\\graph.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open_deep_research\n",
    "import open_deep_research.prompts\n",
    "import open_deep_research.configuration\n",
    "import open_deep_research.utils\n",
    "import open_deep_research.graph\n",
    "from importlib import reload\n",
    "\n",
    "reload(open_deep_research) \n",
    "reload(open_deep_research.prompts)\n",
    "reload(open_deep_research.configuration)\n",
    "reload(open_deep_research.utils) \n",
    "reload(open_deep_research.graph) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph structure\n",
    "# This shows the nodes and edges in the research workflow\n",
    "\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define report structure template and configure the research workflow\n",
    "# This sets parameters for models, search tools, and report organization\n",
    "\n",
    "# REPORT_STRUCTURE = \"\"\"Use this structure to create a report on the user-provided topic:\n",
    "\n",
    "# 1. Introduction (no research needed)\n",
    "#    - Brief overview of the topic area\n",
    "\n",
    "# 2. Main Body Sections:\n",
    "#    - Each section should focus on a sub-topic of the user-provided topic\n",
    "   \n",
    "# 3. Conclusion\n",
    "#    - Aim for 1 structural element (either a list of table) that distills the main body sections \n",
    "#    - Provide a concise summary of the report\"\"\"\n",
    "# topic = \"Overview of Model Context Protocol (MCP), an Anthropic‑backed open standard for integrating external context and tools with LLMs. Give an architectural overview for developers, tell me about interesting MCP servers, and compare to google Agent2Agent (A2A) protocol.\"\n",
    "\n",
    "REPORT_STRUCTURE = \"\"\" \n",
    "第一章、产品质量发展现状\n",
    "   第一节、总体概况：结合当年的数据和政策分析整体情况\n",
    "   第二节、地区概况：结合当年的数据和政策总体分析各地区的概况\n",
    "   第三节、行业概况：结合当年的数据和政策总体分析各行业的概况\n",
    "第二章、地区产品质量状况：包含若干节，（若报告范围为全国则每一节分析一个省份，若报告范围为某省份则每一节分析一个地级市）每一节都聚焦于一个省份或城市的产品质量状况，分析该省份或城市的产品质量发展现状，\n",
    "第三章、行业产品质量状况：包含3-5节，每一节都聚焦于一个特定行业的产品质量状况，分析该行业的产品质量发展现状，比如装备制造类行业、资源加工类行业、食药烟酒类行业以及消费品工业制造业等等\n",
    "\"\"\"\n",
    "\n",
    "CONCLUSION_STRUCTURE = \"\"\"\n",
    "第四章、问题分析：包括3-5节，结合前面章节的内容，分析当前产品质量发展中存在的问题和挑战\n",
    "第五章、政策建议：包括3-5节，提出针对第四章中分析出的问题的解决方案和建议\n",
    "\"\"\"\n",
    "topic = \"湖南省制造业产品质量合格率分析报告（2024年）\"\n",
    "\n",
    "TAVILY_API_KEY = os.environ.get(\"TAVILY_API_KEY\")\n",
    "DEEPSEEK_API_KEY = os.environ.get(\"DEEPSEEK_API_KEY\")\n",
    "DEEPSEEK_MODEL = os.environ.get(\"PLANNER_MODEL\", \"deepseek-chat\")\n",
    "PROVIDER = os.environ.get(\"WRITER_PROVIDER\", \"deepseek\")\n",
    "BASE_URL = 'https://api.deepseek.com/v1'\n",
    "thread = {\"configurable\": {\"thread_id\": str(uuid.uuid4()),\n",
    "                           \"search_api\": \"tavily\",\n",
    "                           \"search_api_config\": {\"api_key\": TAVILY_API_KEY},\n",
    "                           \"planner_provider\": PROVIDER,\n",
    "                           \"planner_model\": DEEPSEEK_MODEL,\n",
    "                           \"planner_model_kwargs\": {\n",
    "                              \"api_key\": DEEPSEEK_API_KEY,\n",
    "                              \"base_url\": BASE_URL\n",
    "                           },\n",
    "                           \"writer_provider\": PROVIDER,\n",
    "                           \"writer_model\": DEEPSEEK_MODEL,\n",
    "                           \"writer_model_kwargs\": {\n",
    "                              \"api_key\": DEEPSEEK_API_KEY,\n",
    "                              \"base_url\": BASE_URL\n",
    "                           },\n",
    "                           \"summarization_model_provider\": PROVIDER,\n",
    "                           \"summarization_model_model\": DEEPSEEK_MODEL,\n",
    "                           \"summarization_model_kwargs\": {\n",
    "                              \"api_key\": DEEPSEEK_API_KEY,\n",
    "                              \"base_url\": BASE_URL\n",
    "                           },      \n",
    "                           \"max_search_depth\": 2,\n",
    "                           \"report_structure\": REPORT_STRUCTURE,\n",
    "                           \"conclusion_structure\": CONCLUSION_STRUCTURE\n",
    "                           }}\n",
    "\n",
    "# Define research topic about Model Context Protocol\n",
    "\n",
    "\n",
    "# Run the graph workflow until first interruption (waiting for user feedback)\n",
    "async for event in graph.astream({\"topic\":topic,}, thread, stream_mode=\"updates\"):\n",
    "   if '__interrupt__' in event:\n",
    "      interrupt_value = event['__interrupt__'][0].value\n",
    "      #   display(Markdown(interrupt_value))\n",
    "      print(\"Interrupt value:\", interrupt_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Feedback Phase\n",
    "\n",
    "* This allows for providing directed feedback on the initial report plan\n",
    "* The user can review the proposed report structure and provide specific guidance\n",
    "* The system will incorporate this feedback into the final report plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入字符串的 Token 数: 65549, 最大限制: 15000\n",
      "输入字符串的 Token 数: 65549, 超过最大限制 15000，已缩减字符串长度到 15904 字符\n",
      "Interrupt value: 请对以下报告框架提供反馈。\n",
      "\n",
      "第1章 产品质量发展现状\n",
      "\t第1节 总体概况\n",
      "\t\t概要: 结合2024年的数据和政策分析湖南省制造业产品质量合格率的整体情况。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第2节 地区概况\n",
      "\t\t概要: 分析湖南省各地区制造业产品质量合格率的总体情况，包括主要数据和政策背景。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第3节 行业概况\n",
      "\t\t概要: 分析湖南省各行业制造业产品质量合格率的总体情况，包括主要数据和政策背景。\n",
      "\t\t是否需要联网搜索: 是\n",
      "第2章 地区产品质量状况\n",
      "\t第1节 长沙市产品质量状况\n",
      "\t\t概要: 分析长沙市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第2节 株洲市产品质量状况\n",
      "\t\t概要: 分析株洲市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第3节 湘潭市产品质量状况\n",
      "\t\t概要: 分析湘潭市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第4节 衡阳市产品质量状况\n",
      "\t\t概要: 分析衡阳市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第5节 邵阳市产品质量状况\n",
      "\t\t概要: 分析邵阳市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第6节 岳阳市产品质量状况\n",
      "\t\t概要: 分析岳阳市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第7节 常德市产品质量状况\n",
      "\t\t概要: 分析常德市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第8节 张家界市产品质量状况\n",
      "\t\t概要: 分析张家界市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第9节 益阳市产品质量状况\n",
      "\t\t概要: 分析益阳市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第10节 郴州市产品质量状况\n",
      "\t\t概要: 分析郴州市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第11节 永州市产品质量状况\n",
      "\t\t概要: 分析永州市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第12节 怀化市产品质量状况\n",
      "\t\t概要: 分析怀化市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第13节 娄底市产品质量状况\n",
      "\t\t概要: 分析娄底市制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第14节 湘西土家族苗族自治州产品质量状况\n",
      "\t\t概要: 分析湘西土家族苗族自治州制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "第3章 行业产品质量状况\n",
      "\t第1节 装备制造类行业产品质量状况\n",
      "\t\t概要: 分析湖南省装备制造类行业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第2节 资源加工类行业产品质量状况\n",
      "\t\t概要: 分析湖南省资源加工类行业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第3节 食药烟酒类行业产品质量状况\n",
      "\t\t概要: 分析湖南省食药烟酒类行业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第4节 消费品工业制造业产品质量状况\n",
      "\t\t概要: 分析湖南省消费品工业制造业产品质量合格率的具体情况，包括数据、政策及典型案例。\n",
      "\t\t是否需要联网搜索: 是\n",
      "第4章 问题分析\n",
      "\t第1节 支柱产业承压下滑，质量管控短板突出\n",
      "\t\t概要: 分析湖南省制造业支柱产业在质量管控方面存在的问题和挑战。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第2节 区域质量发展失衡，湘西地区水平落后\n",
      "\t\t概要: 分析湖南省各地区制造业质量发展不平衡的问题，特别是湘西地区的落后情况。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第3节 新兴产业波动加剧，质量稳定有待加强\n",
      "\t\t概要: 分析湖南省新兴产业在质量稳定性方面的问题和挑战。\n",
      "\t\t是否需要联网搜索: 是\n",
      "\t第4节 小型企业基础薄弱，存在质量安全隐患\n",
      "\t\t概要: 分析湖南省小型制造业企业在质量安全方面的薄弱环节和隐患。\n",
      "\t\t是否需要联网搜索: 是\n",
      "第5章 政策建议\n",
      "\t第1节 优化完善市场监管手段措施，防范化解重点领域质量风险问题\n",
      "\t\t概要: 提出优化市场监管手段的建议，以防范和化解重点领域的质量风险。\n",
      "\t\t是否需要联网搜索: 否\n",
      "\t第2节 深入推进质量强企强链强县建设，提升产业链韧性及区域发展协同性\n",
      "\t\t概要: 提出加强质量强企、强链、强县建设的建议，以提升产业链韧性和区域协同发展。\n",
      "\t\t是否需要联网搜索: 否\n",
      "\t第3节 构建高水平质量基础设施建设体系，发挥服务质量提升的支撑保障作用\n",
      "\t\t概要: 提出构建高水平质量基础设施体系的建议，以支撑和保障服务质量提升。\n",
      "\t\t是否需要联网搜索: 否\n",
      "\n",
      "\n",
      "    \n",
      "该报告框架是否符合您的需求？\n",
      "输入'true'以确认采用该报告框架。\n",
      "或提供修改意见以重新生成报告框架：\n"
     ]
    }
   ],
   "source": [
    "# Submit feedback on the report plan\n",
    "# The system will continue execution with the updated requirements\n",
    "\n",
    "# Provide specific feedback to focus and refine the report structure\n",
    "async for event in graph.astream(Command(resume=\"第二章的地区不够多，把湖南省的地级市都包括，每一个地级市一节\"), thread, stream_mode=\"updates\"):\n",
    "    if '__interrupt__' in event:\n",
    "        interrupt_value = event['__interrupt__'][0].value\n",
    "        print(\"Interrupt value:\", interrupt_value)\n",
    "        # display(Markdown(interrupt_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Approval Phase\n",
    "* After incorporating feedback, approve the plan to start content generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approve the final plan and execute the report generation\n",
    "# This triggers the research and writing phases for all sections\n",
    "\n",
    "# The system will now:\n",
    "# 1. Research each section topic\n",
    "# 2. Generate content with citations\n",
    "# 3. Create introduction and conclusion\n",
    "# 4. Compile the final report\n",
    "\n",
    "async for event in graph.astream(Command(resume=True), thread, stream_mode=\"updates\"):\n",
    "    print(event)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Introduction  \n",
       "Large language models excel at reasoning, but without structured access to the outside world they remain isolated. The Model Context Protocol (MCP) bridges this gap, defining an open, vendor‑neutral way for models to tap files, databases, APIs, and other tools through simple JSON‑RPC exchanges. This report walks developers through the protocol’s architecture, surveys real‑world MCP servers that showcase its flexibility, and contrasts MCP with Google’s emerging Agent‑to‑Agent (A2A) standard. By the end, you should know when, why, and how to weave MCP into your own agentic systems.\n",
       "\n",
       "## MCP Architectural Overview for Developers\n",
       "\n",
       "MCP uses a client‑host‑server model: a host process spawns isolated clients, and every client keeps a 1‑to‑1, stateful session with a single server that exposes prompts, resources, and tools through JSON‑RPC 2.0 messages [1][5].  \n",
       "\n",
       "A session passes through three phases — initialize, operation, shutdown. The client begins with an initialize request that lists its protocolVersion and capabilities; the server replies with a compatible version and its own capabilities. After the client’s initialized notification, both sides may exchange requests, responses, or one‑way notifications under the agreed capabilities [2].  \n",
       "\n",
       "Two official transports exist. Stdio is ideal for local child processes, while HTTP (SSE/“streamable HTTP”) supports multi‑client, remote scenarios. Both must preserve JSON‑RPC framing, and servers should validate Origin headers, bind to localhost where possible, and apply TLS or authentication to block DNS‑rebind or similar attacks [1][3].  \n",
       "\n",
       "To integrate MCP, developers can:  \n",
       "1) implement a server that registers needed primitives and advertises them in initialize.result.capabilities;  \n",
       "2) validate all inputs and set reasonable timeouts;  \n",
       "3) or consume existing servers via SDKs—select a transport, send initialize, then invoke or subscribe to tools/resources exactly as negotiated [4][5].  \n",
       "\n",
       "### Sources  \n",
       "[1] MCP Protocol Specification: https://www.claudemcp.com/specification  \n",
       "[2] Lifecycle – Model Context Protocol: https://modelcontextprotocol.info/specification/draft/basic/lifecycle/  \n",
       "[3] Transports – Model Context Protocol: https://modelcontextprotocol.io/specification/2025-03-26/basic/transports  \n",
       "[4] Core Architecture – Model Context Protocol: https://modelcontextprotocol.io/docs/concepts/architecture  \n",
       "[5] Architecture – Model Context Protocol Specification: https://spec.modelcontextprotocol.io/specification/2025-03-26/architecture/\n",
       "\n",
       "## Ecosystem Spotlight: Notable MCP Servers\n",
       "\n",
       "Hundreds of MCP servers now exist, spanning core data access, commercial platforms, and hobby projects—proof that the protocol can wrap almost any tool or API [1][2].\n",
       "\n",
       "Reference servers maintained by Anthropic demonstrate the basics.  Filesystem, PostgreSQL, Git, and Slack servers cover file I/O, SQL queries, repository ops, and chat workflows.  Developers can launch them in seconds with commands like  \n",
       "`npx -y @modelcontextprotocol/server-filesystem` (TypeScript) or `uvx mcp-server-git` (Python) and then point any MCP‑aware client, such as Claude Desktop, at the spawned process [1].\n",
       "\n",
       "Platform vendors are adding “first‑party” connectors.  Microsoft cites the GitHub MCP Server and a Playwright browser‑automation server as popular examples that let C# or .NET apps drive code reviews or end‑to‑end tests through a uniform interface [3].  Other partner servers—e.g., Cloudflare for edge resources or Stripe for payments—expose full product APIs while still enforcing user approval through MCP’s tool‑calling flow [2].\n",
       "\n",
       "Community builders rapidly fill remaining gaps.  Docker and Kubernetes servers give agents controlled shell access; Snowflake, Neon, and Qdrant handle cloud databases; Todoist and Obsidian servers tackle personal productivity.  Because every server follows the same JSON‑RPC schema and ships as a small CLI, developers can fork an existing TypeScript or Python implementation and swap in their own SDK calls to create new connectors in hours, not weeks [2].  \n",
       "\n",
       "### Sources  \n",
       "[1] Example Servers – Model Context Protocol: https://modelcontextprotocol.io/examples  \n",
       "[2] Model Context Protocol Servers Repository: https://github.com/madhukarkumar/anthropic-mcp-servers  \n",
       "[3] Microsoft partners with Anthropic to create official C# SDK for Model Context Protocol: https://devblogs.microsoft.com/blog/microsoft-partners-with-anthropic-to-create-official-c-sdk-for-model-context-protocol\n",
       "\n",
       "## Agent‑to‑Agent (A2A) Protocol and Comparison with MCP  \n",
       "\n",
       "Google’s Agent‑to‑Agent (A2A) protocol, announced in April 2025, gives autonomous agents a common way to talk directly across vendors and clouds [2]. Its goal is to let one “client” agent delegate work to a “remote” agent without sharing internal code or memory, enabling true multi‑agent systems.  \n",
       "\n",
       "Discovery starts with a JSON Agent Card served at /.well‑known/agent.json, which lists version, skills and endpoints [3]. After discovery, the client opens a Task—an atomic unit that moves through states and exchanges Messages and multimodal Artifacts. HTTP request/response, Server‑Sent Events, or push notifications are chosen based on task length to stream progress safely [2].  \n",
       "\n",
       "Anthropic’s Model Context Protocol (MCP) tackles a different layer: it links a single language model to external tools and data through a Host‑Client‑Server triad, exposing Resources, Tools and Prompts over JSON‑RPC [1]. Communication is model‑to‑tool, not agent‑to‑agent.  \n",
       "\n",
       "Google therefore calls A2A “complementary” to MCP: use MCP to give each agent the data and actions it needs; use A2A to let those empowered agents discover one another, coordinate plans and exchange results [1]. In practice, developers might pipe an A2A task that, mid‑flow, invokes an MCP tool or serve an MCP connector as an A2A remote agent, showing the standards can interlock instead of compete.  \n",
       "\n",
       "### Sources  \n",
       "[1] MCP vs A2A: Comprehensive Comparison of AI Agent Protocols: https://www.toolworthy.ai/blog/mcp-vs-a2a-protocol-comparison  \n",
       "[2] Google A2A vs MCP: The New Protocol Standard Developers Need to Know: https://www.trickle.so/blog/google-a2a-vs-mcp  \n",
       "[3] A2A vs MCP: Comparing AI Standards for Agent Interoperability: https://www.ikangai.com/a2a-vs-mcp-ai-standards/\n",
       "\n",
       "## Conclusion\n",
       "\n",
       "Model Context Protocol (MCP) secures a model’s immediate tool belt, while Google’s Agent‑to‑Agent (A2A) protocol enables those empowered agents to find and hire one another. Their scopes differ but interlock, giving developers a layered recipe for robust, multi‑agent applications.\n",
       "\n",
       "| Aspect | MCP | A2A |\n",
       "| --- | --- | --- |\n",
       "| Layer | Model‑to‑tool RPC | Agent‑to‑agent orchestration |\n",
       "| Session start | `initialize` handshake | Task creation lifecycle |\n",
       "| Discovery | Client‑supplied server URI | `/.well‑known/agent.json` card |\n",
       "| Streaming | Stdio or HTTP/SSE | HTTP, SSE, or push |\n",
       "| Best fit | Embed filesystems, DBs, SaaS APIs into one agent | Delegate subtasks across clouds or vendors |\n",
       "\n",
       "Next steps: prototype an A2A task that internally calls an MCP PostgreSQL server; harden both layers with TLS and capability scoping; finally, contribute a new open‑source MCP connector to accelerate community adoption."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the final generated report\n",
    "# Retrieve the completed report from the graph's state and format it for display\n",
    "\n",
    "final_state = graph.get_state(thread)\n",
    "report = final_state.values.get('final_report')\n",
    "Markdown(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "> Note: uses 80k tokens \n",
    "\n",
    "https://smith.langchain.com/public/31eca7c9-beae-42a3-bef4-5bce9488d7be/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
